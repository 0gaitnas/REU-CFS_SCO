{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix diagonalization\n",
    "** Burton Rosenberg, May 2017**\n",
    "\n",
    "A matrix is a linear map between vector spaces. To understand the transformation, we consider the matrix as an _endomorphism_, a map of the vector space back to itself, and look for invariant subspaces. An _invariant subspace_ is a linear subspace of the vector space that is mapped by the matrix back into itself. In particular, if the invariant supspace is one dimensional, that on that subspace the matrix acts as a pure scaling.\n",
    "\n",
    "To find a one dimensional invariant subspace, we write down the property of a vector in such a subspace:\n",
    "$$\n",
    "     \\lambda v = M v\n",
    "$$\n",
    "where $\\lambda$ is a scalar and $M$ is the matrix. The vector $v$ and the scalar $\\lambda$ are to be determined. The  $v$,  \\lambda$ pair are called the _eigvenvector_ along with its associated _eigenvalue_, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples:\n",
    "\n",
    "Find three distinct eigenvalue-eigenvectors pairs of this matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def isgood(m,evect,evalue):\n",
    "    return np.array_equal(m.dot(evect), evalue*evect)\n",
    "\n",
    "m1 = np.array([[1,0,0],[0,2,0],[0,0,3]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the tests true. BTW, eigenvectors must be non-zero, so the fact that the tests are passed by $v=0$ and $e=0$ does not count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Name me some eigenvalues\n",
    "\"\"\"\n",
    "\n",
    "v1 = np.ones(3) ; e1 = 0\n",
    "v2 = np.ones(3) ; e2 = 0\n",
    "v3 = np.ones(3) ; e3 = 0 \n",
    "\n",
    "print isgood(m1,v1,e1)\n",
    "print isgood(m1,v2,e2)\n",
    "print isgood(m1,v2,e2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniqueness of eigenvectors\n",
    "\n",
    "Congratulations on finding the eigenvectors and eigenvalues. \n",
    "\n",
    "Note that the eigenvalues are distinct. This means that the three eigenvectors you found are all the possible eigenvectors. Consider matrix M2.\n",
    "\n",
    "Make the tests true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product test: False\n",
      "Vectors are not distinct\n",
      "Eigenspace test: False\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The challenge: \n",
    "\n",
    "Find the eigenspace of m2. Respond with v4, v5, e45 so that v4 and v5 \n",
    "span the eigenspace, and e45 is the common eigenvalue of v4 and v5.\n",
    "\"\"\"\n",
    "\n",
    "m2 = np.array([[3,0,0],[0,3,0],[0,0,4]])\n",
    "\n",
    "v4 = np.array([0,0,0],dtype=\"float\")\n",
    "v5 = np.array([0,0,0],dtype=\"float\")\n",
    "e45 = 0.0\n",
    "\n",
    "def linear_mix(a,v,b,w):\n",
    "    \"\"\"\n",
    "    Given floats a and b, and vectors v and w, return a*v+b*2\n",
    "    (you have to write this)\n",
    "    \"\"\"\n",
    "    return np.ones(len(v))\n",
    "\n",
    "## the tests\n",
    "\n",
    "import random\n",
    "\n",
    "def test_linear_mix():\n",
    "    tvs = np.array([random.randint(0,100) for i in range(9)]).reshape(3,3)\n",
    "    tal = 0.25\n",
    "    tlin = linear_mix(tal,tvs[0],1.0-tal,tvs[1])\n",
    "    return tlin.dot(tvs[2]) == (tal*tvs[2].dot(tvs[0])+(1.0-tal)*tvs[2].dot(tvs[1]))\n",
    "\n",
    "def test_eigenspace(v4,v5,e45):\n",
    "    if np.array_equal(v4,v5):\n",
    "        print \"ErrorL vectors are not distinct\"\n",
    "        return False\n",
    "    for alpha in np.linspace(0,1,5,dtype=float):\n",
    "        v = linear_mix(alpha,v4,1.0-alpha,v5)\n",
    "        if not isgood(m2,v,e45):\n",
    "            print \"Error: vector is not in an invariant subspace\"\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "print \"Dot product test:\", test_linear_mix()\n",
    "result=test_eigenspace(v4,v5,e45)\n",
    "print \"Eigenspace test:\", result\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving for eigenvectors\n",
    "\n",
    "The equation defining eigenvectors can be rearranged:\n",
    "$$\n",
    "(\\lambda\\, I - M) \\cdot v = 0\n",
    "$$\n",
    "For a non-zero $v$ to solve this equation the matrix must be singular, and the vector in the left null space. With $\\lambda$ considered an unknown, that leds to solving the equation,\n",
    "$$\n",
    "det(\\lambda\\,I-M) = 0\n",
    "$$\n",
    "This is called the _characteristic equation_.\n",
    "While it is tedious to write out the equation for the determinate in the unknown $\\lambda$, we do know that it is a cubic in $\\lambda$, and therefore has three solutions over the complex numbers.\n",
    "\n",
    "We also know that the complex solutions, if any, will come in conjugate pairs, and therefore at least on eigenvalue is real.\n",
    "\n",
    "Write the code to verify you eigenvalues given in the above challenge. See the [numpy reference for linalg.det](https://docs.scipy.org/doc/numpy-1.12.0/reference/generated/numpy.linalg.det.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False False\n"
     ]
    }
   ],
   "source": [
    "def char_eqn(m,lmb):\n",
    "    \"\"\"\n",
    "    Returns True if lmb is a root of the characteristic equation of matrix m.\n",
    "    \"\"\"\n",
    "    return False\n",
    "\n",
    "print char_eqn(m1,e1),char_eqn(m1,e2),char_eqn(m1,e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagonalization part 1: eigenvalues\n",
    "\n",
    "Find the eigenvalues of matrix m3. _Hint:_ you can always binary search for the zero. There is probably a numby call that calculates eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ -3.15153646e-01,   6.32991453e-01,  -7.07106781e-01],\n",
       "        [ -3.15153646e-01,   6.32991453e-01,   7.07106781e-01],\n",
       "        [  8.95185098e-01,   4.45694560e-01,  -1.80411242e-16]]),\n",
       " array([ 5.02183692,  3.98260643,  3.        ]),\n",
       " array([[ -3.34881315e-01,  -3.34881315e-01,   8.80743441e-01],\n",
       "        [  6.22779660e-01,   6.22779660e-01,   4.73593698e-01],\n",
       "        [ -7.07106781e-01,   7.07106781e-01,  -5.55111512e-17]]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3 = np.array([[ 3.6,0.6,-0.2],[0.6,3.6,-0.2],[-0.4,-0.4,4.8]])\n",
    "\n",
    "e31 = 0.0\n",
    "e32 = 0.0\n",
    "e33 = 0.0\n",
    "\n",
    "print char_eqn(m3,e1),char_eqn(m3,e2),char_eqn(m3,e3)\n",
    "\n",
    "np.linalg.svd(m3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagonalization part 2: eigenvectors\n",
    "\n",
    "The eigenvectors are the three vectors that solve the equation $(\\lambda\\,I-M)\\cdot v_i=0$.\n",
    "\n",
    "This can be done by backsolving, or using a numby call to solving a matrix equation. In this case, this should be the vector in the one-dimensional null space of the matrix resulting from evaluating the characteristic equation at the eigenvalue. When \"shifted\" away from singularity, it becomes the invariant space.\n",
    "\n",
    "Find these three vectors for m3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "v31 = np.array([0,0,0])\n",
    "v32 = np.array([0,0,0])\n",
    "v33 = np.array([0,0,0])\n",
    "\n",
    "def eval_ce(lm,m,v):\n",
    "    return (lm*np.eye(3)-m).cdot(v)\n",
    "\n",
    "print eval_ce(m3,e31,c31).array_equal(np.zeros(3)),\n",
    "    eval_ce(m3,e32,c32).array_equal(np.zeros(3)),\n",
    "    eval_ce(m3,e32,c32).array_equal(np.zeros(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagonalization part 3: Singular Value Decomposition\n",
    "\n",
    "Because the eigenvalues are distinct, the eigenvectors must be linearly independent (why?). That means they must span the three dimensional space, and can be used as an alternative coordiante system. That is, for a vector $v$, there is a unique triple $(x,y,z)$ such that\n",
    "$$\n",
    "v = x v_1 + y v_2 + z v_3\n",
    "$$\n",
    "So this triple is the coordinate of $v$ in the coordinate system with basis $(v_1,v_2,v_3)$.\n",
    "\n",
    "So decomposed, the vector passes through the transformation with each coordinate scaled individualy by the eigenvalue associated with the eigenvector. The new coordiantes can then be reexpressed in the standard basis by applying the coordinate to the associated eigenvector then summing.\n",
    "\n",
    "This can be carried out by hand, but it can also be found in the numby linear alegrebra package, under the name _singular value decomposition_. The SVD is the basis for many other statistical tests, and alternative decompositions differ in numerical stability, but not in the conceptual framework.\n",
    "\n",
    "Write the SVD decomposition of m3. Note that the diagonal matrix is the diagonal of eigenvalues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
